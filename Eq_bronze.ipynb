{"cells":[{"cell_type":"markdown","source":["# <b>Earthquake Events - Bronze layer"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"330e3e30-8d25-4ad3-9d0b-93fa5ffbc24a"},{"cell_type":"markdown","source":["#### <B>Fetching data from the API URL\n","1. Checking for the status code t to make sure URL is connected\n","2. Creating file path string connection\n","3. Writing the file to the file path"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"15df3d25-7dda-47cb-99e5-5046048de13e"},{"cell_type":"code","source":["import requests\n","import json\n","\n","# Getting the API url and storing it into a variable\n","#---we have start_date and end_date as variable which can be set to get target date informtaion and this can be passed through pipline setup\n","url = \"https://earthquake.usgs.gov/fdsnws/event/1/query?format=geojson&starttime={start_date}&endtime={end_date}\"\n","\n","# Makeing a GET request and store it in a variable.\n","response = requests.get(url)\n","\n","#Check if the response is sucessful or not by checking the return status code value is 200 or not\n","if response.status_code == 200:\n","    data = response.json()['features']\n","    #Open the file path instance and set the attribute to write\n","    file_path = f'/lakehouse/default/Files/{start_date}_earthquake_date.json'\n","    with open(file_path,'w') as file:\n","        json.dump(data,file,indent=4)\n","    print(f\"Data scucessfully saved to {file_path}\",response.status_code)\n","else:\n","    print(f\"File did not save\",response.status_code)  \n","\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":7,"statement_ids":[7],"state":"finished","livy_statement_state":"available","session_id":"6b5a1ffa-9483-4858-82c2-ba1a9cbcae7e","normalized_state":"finished","queued_time":"2025-11-08T00:57:44.6846857Z","session_start_time":null,"execution_start_time":"2025-11-08T00:57:44.6858015Z","execution_finish_time":"2025-11-08T00:57:46.1131552Z","parent_msg_id":"b7720a59-da8e-485d-8c8b-1a062412fb02"},"text/plain":"StatementMeta(, 6b5a1ffa-9483-4858-82c2-ba1a9cbcae7e, 7, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Data scucessfully saved to /lakehouse/default/Files/2025-11-01_earthquake_date.json 200\n"]}],"execution_count":5,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"319d0ece-6b9d-4bd6-a234-03f9bf7ebd85"},{"cell_type":"code","source":["### How start_dte and end_date work\n","#from datetime import date,timedelta\n","#start_date = date.today()-timedelta(7)\n","#end_date= date.today()-timedelta(1)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2eaa68ca-b683-4bf1-a2ca-81311f78f699"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"synapse_widget":{"version":"0.1","state":{}},"dependencies":{"lakehouse":{"default_lakehouse":"9d00d14c-3a4f-4f64-8194-bd1a616bdf20","known_lakehouses":[{"id":"9d00d14c-3a4f-4f64-8194-bd1a616bdf20"}],"default_lakehouse_name":"earthquake_lakehouse","default_lakehouse_workspace_id":"31a6ec20-d80d-40d6-8ef8-3e5ec9c75ac3"}}},"nbformat":4,"nbformat_minor":5}